{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "768c296d",
   "metadata": {},
   "source": [
    "# ERS NIRCam Demo with Eureka!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98121beb",
   "metadata": {},
   "source": [

    "\n",
    "## Authors: Megan Mansfield and Eva-Maria Ahrer\n",
    " Hello! This notebook shows a full demonstration reducing and analyzing the NIRCam/F322W2 transit of WASP-39b from the JWST Transiting Exoplanet Early Release Science Program (ERS 1366). Following this pipeline, you should be able to reproduce the NIRCam spectrum presented in the main text of Ahrer et al. (2022). \n",
    " \n",
    "This data reduction uses the [Eureka!](https://github.com/kevin218/Eureka) pipeline. Before running this Jupyter Notebook, please follow the steps in \"README.md\" to set up an environment for this demonstration and install Eureka. Note that this demonstration is using a fixed version of Eureka! to ensure that no future updates break the example here, so even if you have the current version of Eureka! installed on your own machine you'll need to follow the set-up steps to ensure this demo works properly. For more information on Eureka! see its documentation or refer to Bell et al. (2022)."

   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a66542c",
   "metadata": {},
   "source": [
    "### First, download the data set.\n",
    "#### Data can be downloaded from MAST at: (DOI? Specify which file extensions/stage?)\n",
    "After downloading the data, place it in a directory \"./Uncalibrated\" within this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc8ab40",
   "metadata": {},
   "source": [
    "### Next, let's import packages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b26757b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-06 11:41:01,719 - stpipe - WARNING - No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./')\n",
    "sys.path.insert(0,'./')\n",
    "import eureka.S1_detector_processing.s1_process as s1\n",
    "import eureka.S2_calibrations.s2_calibrate as s2\n",
    "import eureka.S3_data_reduction.s3_reduce as s3\n",
    "import eureka.S4_generate_lightcurves.s4_genLC as s4\n",
    "import eureka.S5_lightcurve_fitting.s5_fit as s5\n",
    "import eureka.S6_planet_spectra.s6_spectra as s6\n",
    "\n",
    "from eureka.lib import readECF\n",
    "\n",
    "eventlabel = 'nircam_wasp39b'\n",
    "ecf_path = './ecf/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6b7d52",
   "metadata": {},
   "source": [
    "#### Note: Eureka! is divided into six \"Stages\". Each Stage has a corresponding Eureka! Control File or .ecf file, and in Stage 5 there's also a Eureka! Parameter File or .epf. \n",
    "These files are named \"S2_eventlabel.ecf\" where the first half of the name (S2, S3, etc.) refers to the Stage that .ecf file interacts with, and the second half refers to the \"eventlabel\" keyword we defined above. See the Eureka! documentation for a full description of each stage and all keywords in the .ecf files. Here we'll give a very brief summary of each Stage and discuss a few important keywords for reproducing the paper results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236a961d",
   "metadata": {},
   "source": [
    "# Stage 1: Correcting detector-level effects and fitting the up-the-ramp slope.\n",
    "#### Most important keywords in the .ecf:\n",
    "1. jump_rejection_threshold - this sets the sigma threshold for rejecting a jump in the up-the-ramp slope as due to a cosmic ray hit. The standard value in the jwst pipeline is 4.0, but this data reduction found a value of 6.0 produced better results.\n",
    "2. topdir - Edit this to make it the path to where you've downloaded the data for this demo. The path should look like this: /path/to/NIRCam_demo/wasp39b_data/\n",
    "3. inputdir - This keyword tells Eureka! where to look for the Uncalibrated outputs to feed into the Stage 1 code. This path is relative to \"topdir\". In this demo, we set inputdir=/Uncalibrated\n",
    "4. outputdir - This is where Eureka! will save all the Stage 2 outputs, including plots and log files. Here we set outputdir=/Stage1, which means the output files will be saved within a folder on the path /path/to/NIRCam_demo/NIRCam_full_data/Stage1/\n",
    "#### Note that topdir, inputdir, and outputdir work the same in every .ecf file, so in each file edit them so that \"inputdir\" points to the previous Stage's outputs, and \"outputdir\" points to where you want to save that Stage's outputs."
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 20,
   "id": "6aa3919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecffile = 'S1_' + eventlabel + '.ecf'\n",
    "input_meta_S1 = readECF.MetaClass(ecf_path, ecffile)\n",
    "\n",
    "input_meta_S1.jump_rejection_threshold = 4.0\n",
    "input_meta_S1.topdir = '/storage/astro2/phrgmk/Data/JWST/NIRCam/WASP-39/'\n",
    "input_meta_S1.inputdir = input_meta_S1.topdir + '/Uncalibrated/'\n",
    "input_meta_S1.outputdir = input_meta_S1.topdir + '/Stage1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef77f50",
   "metadata": {},
   "source": [
    "### And that's it! Let's run Stage 1!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,

   "id": "2abecad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Stage 1 Processing\n",

      "Input directory: /Users/megan/Documents/Code/ERS_NIRCam/ERS_NIRCam/Uncalibrated/\n",
      "Output directory: /Users/megan/Documents/Code/ERS_NIRCam/ERS_NIRCam/Stage1/S1_2022-10-04_nircam_wasp39b_run1/\n",

      "Copying S1 control file\n",
      "\n",
      "Found 4 data file(s) ending in uncal.fits\n",
      "Starting file 1 of 4: jw01366002001_04103_00001-seg001_nrcalong_uncal.fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [

      "2022-10-04 14:38:25,009 - stpipe.EurekaS1Pipeline - INFO - EurekaS1Pipeline instance created.\n",
      "2022-10-04 14:38:25,011 - stpipe.EurekaS1Pipeline.group_scale - INFO - GroupScaleStep instance created.\n",
      "2022-10-04 14:38:25,013 - stpipe.EurekaS1Pipeline.dq_init - INFO - DQInitStep instance created.\n",
      "2022-10-04 14:38:25,015 - stpipe.EurekaS1Pipeline.saturation - INFO - SaturationStep instance created.\n",
      "2022-10-04 14:38:25,017 - stpipe.EurekaS1Pipeline.ipc - INFO - IPCStep instance created.\n",
      "2022-10-04 14:38:25,018 - stpipe.EurekaS1Pipeline.superbias - INFO - SuperBiasStep instance created.\n",
      "2022-10-04 14:38:25,020 - stpipe.EurekaS1Pipeline.refpix - INFO - RefPixStep instance created.\n",
      "2022-10-04 14:38:25,022 - stpipe.EurekaS1Pipeline.rscd - INFO - RscdStep instance created.\n",
      "2022-10-04 14:38:25,024 - stpipe.EurekaS1Pipeline.firstframe - INFO - FirstFrameStep instance created.\n",
      "2022-10-04 14:38:25,026 - stpipe.EurekaS1Pipeline.lastframe - INFO - LastFrameStep instance created.\n",
      "2022-10-04 14:38:25,028 - stpipe.EurekaS1Pipeline.linearity - INFO - LinearityStep instance created.\n",
      "2022-10-04 14:38:25,030 - stpipe.EurekaS1Pipeline.dark_current - INFO - DarkCurrentStep instance created.\n",
      "2022-10-04 14:38:25,031 - stpipe.EurekaS1Pipeline.reset - INFO - ResetStep instance created.\n",
      "2022-10-04 14:38:25,033 - stpipe.EurekaS1Pipeline.persistence - INFO - PersistenceStep instance created.\n",
      "2022-10-04 14:38:25,035 - stpipe.EurekaS1Pipeline.jump - INFO - JumpStep instance created.\n",
      "2022-10-04 14:38:25,036 - stpipe.EurekaS1Pipeline.ramp_fit - INFO - RampFitStep instance created.\n",
      "2022-10-04 14:38:25,037 - stpipe.EurekaS1Pipeline.gain_scale - INFO - GainScaleStep instance created.\n",
      "2022-10-04 14:38:25,042 - stpipe.Eureka_RampFitStep - INFO - Eureka_RampFitStep instance created.\n",
      "2022-10-04 14:38:25,112 - stpipe.EurekaS1Pipeline - INFO - Step EurekaS1Pipeline running with args ('/Users/megan/Documents/Code/ERS_NIRCam/ERS_NIRCam/Uncalibrated/jw01366002001_04103_00001-seg001_nrcalong_uncal.fits',).\n",
      "2022-10-04 14:38:25,119 - stpipe.EurekaS1Pipeline - INFO - Step EurekaS1Pipeline parameters are: {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': '/Users/megan/Documents/Code/ERS_NIRCam/ERS_NIRCam/Stage1/S1_2022-10-04_nircam_wasp39b_run1/', 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': True, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': '', 'save_calibrated_ramp': False, 'steps': {'group_scale': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': ''}, 'dq_init': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': ''}, 'saturation': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': '', 'n_pix_grow_sat': 1}, 'ipc': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': True, 'suffix': None, 'search_output_file': True, 'input_dir': ''}, 'superbias': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': ''}, 'refpix': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': '', 'odd_even_columns': True, 'use_side_ref_pixels': True, 'side_smoothing_length': 11, 'side_gain': 1.0, 'odd_even_rows': True}, 'rscd': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': '', 'type': 'baseline'}, 'firstframe': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': ''}, 'lastframe': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': ''}, 'linearity': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': ''}, 'dark_current': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': '', 'dark_output': None}, 'reset': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': ''}, 'persistence': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': True, 'suffix': None, 'search_output_file': True, 'input_dir': '', 'input_trapsfilled': '', 'flag_pers_cutoff': 40.0, 'save_persistence': False, 'save_trapsfilled': True}, 'jump': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': '', 'rejection_threshold': 6.0, 'three_group_rejection_threshold': 6.0, 'four_group_rejection_threshold': 5.0, 'maximum_cores': 'none', 'flag_4_neighbors': True, 'max_jump_to_flag_neighbors': 1000.0, 'min_jump_to_flag_neighbors': 10.0}, 'ramp_fit': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': '', 'int_name': '', 'save_opt': False, 'opt_name': '', 'maximum_cores': 'half'}, 'gain_scale': {'pre_hooks': [], 'post_hooks': [], 'output_file': None, 'output_dir': None, 'output_ext': '.fits', 'output_use_model': False, 'output_use_index': True, 'save_results': False, 'skip': False, 'suffix': None, 'search_output_file': True, 'input_dir': ''}}}\n",
      "2022-10-04 14:38:25,197 - stpipe.EurekaS1Pipeline - WARNING - /Users/megan/opt/anaconda3/envs/ers-nircam/lib/python3.9/site-packages/asdf/entry_points.py:46: AsdfWarning: asdf.extensions plugin from package asdf-astropy==0.2.2 failed to load:\n",
      "\n",
      "ContextualVersionConflict: (jsonschema 4.16.0 (/Users/megan/opt/anaconda3/envs/ers-nircam/lib/python3.9/site-packages), Requirement.parse('jsonschema<4.10.0,>=4.0.1'), {'asdf'})\n",
      "  warnings.warn(\n",
      "\n",
      "2022-10-04 14:38:25,212 - stpipe.EurekaS1Pipeline - WARNING - /Users/megan/opt/anaconda3/envs/ers-nircam/lib/python3.9/site-packages/asdf/entry_points.py:46: AsdfWarning: asdf.extensions plugin from package gwcs==0.18.2 failed to load:\n",
      "\n",
      "ContextualVersionConflict: (jsonschema 4.16.0 (/Users/megan/opt/anaconda3/envs/ers-nircam/lib/python3.9/site-packages), Requirement.parse('jsonschema<4.10.0,>=4.0.1'), {'asdf'})\n",
      "  warnings.warn(\n",
      "\n",
      "2022-10-04 14:38:25,420 - stpipe.EurekaS1Pipeline - WARNING - /Users/megan/opt/anaconda3/envs/ers-nircam/lib/python3.9/site-packages/asdf/entry_points.py:46: AsdfWarning: asdf.extensions plugin from package jwst==1.6.0 failed to load:\n",
      "\n",
      "ContextualVersionConflict: (jsonschema 4.16.0 (/Users/megan/opt/anaconda3/envs/ers-nircam/lib/python3.9/site-packages), Requirement.parse('jsonschema<4.10.0,>=4.0.1'), {'asdf'})\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 14:38:25,443 - stpipe.EurekaS1Pipeline - WARNING - /Users/megan/opt/anaconda3/envs/ers-nircam/lib/python3.9/site-packages/asdf/entry_points.py:46: AsdfWarning: asdf_extensions plugin from package jwst==1.6.0 failed to load:\n",
      "\n",
      "ContextualVersionConflict: (jsonschema 4.16.0 (/Users/megan/opt/anaconda3/envs/ers-nircam/lib/python3.9/site-packages), Requirement.parse('jsonschema<4.10.0,>=4.0.1'), {'asdf'})\n",
      "  warnings.warn(\n",
      "\n",
      "2022-10-04 14:38:25,444 - stpipe.EurekaS1Pipeline - WARNING - /Users/megan/opt/anaconda3/envs/ers-nircam/lib/python3.9/site-packages/asdf/entry_points.py:46: AsdfWarning: asdf_extensions plugin from package stpipe==0.4.2 failed to load:\n",
      "\n",
      "ContextualVersionConflict: (jsonschema 4.16.0 (/Users/megan/opt/anaconda3/envs/ers-nircam/lib/python3.9/site-packages), Requirement.parse('jsonschema<4.10.0,>=4.0.1'), {'asdf'})\n",
      "  warnings.warn(\n",
      "\n",
      "2022-10-04 14:38:25,445 - stpipe.EurekaS1Pipeline - WARNING - /Users/megan/opt/anaconda3/envs/ers-nircam/lib/python3.9/site-packages/asdf/entry_points.py:46: AsdfWarning: asdf_extensions plugin from package asdf==2.13.0 failed to load:\n",
      "\n",
      "VersionConflict: (jsonschema 4.16.0 (/Users/megan/opt/anaconda3/envs/ers-nircam/lib/python3.9/site-packages), Requirement.parse('jsonschema<4.10.0,>=4.0.1'))\n",
      "  warnings.warn(\n",
      "\n",
      "2022-10-04 14:38:25,447 - stpipe.EurekaS1Pipeline - WARNING - /Users/megan/opt/anaconda3/envs/ers-nircam/lib/python3.9/site-packages/asdf/entry_points.py:46: AsdfWarning: asdf.resource_mappings plugin from package asdf-astropy==0.2.2 failed to load:\n",
      "\n",
      "ContextualVersionConflict: (jsonschema 4.16.0 (/Users/megan/opt/anaconda3/envs/ers-nircam/lib/python3.9/site-packages), Requirement.parse('jsonschema<4.10.0,>=4.0.1'), {'asdf'})\n",
      "  warnings.warn(\n",
      "\n",
      "2022-10-04 14:38:25,448 - stpipe.EurekaS1Pipeline - WARNING - /Users/megan/opt/anaconda3/envs/ers-nircam/lib/python3.9/site-packages/asdf/entry_points.py:46: AsdfWarning: asdf.resource_mappings plugin from package asdf-coordinates-schemas==0.1.0 failed to load:\n",
      "\n",
      "ContextualVersionConflict: (jsonschema 4.16.0 (/Users/megan/opt/anaconda3/envs/ers-nircam/lib/python3.9/site-packages), Requirement.parse('jsonschema<4.10.0,>=4.0.1'), {'asdf'})\n",
      "  warnings.warn(\n",
      "\n",
      "2022-10-04 14:38:25,455 - stpipe.EurekaS1Pipeline - WARNING - /Users/megan/opt/anaconda3/envs/ers-nircam/lib/python3.9/site-packages/asdf/entry_points.py:46: AsdfWarning: asdf.resource_mappings plugin from package asdf-wcs-schemas==0.1.1 failed to load:\n",
      "\n",
      "ContextualVersionConflict: (jsonschema 4.16.0 (/Users/megan/opt/anaconda3/envs/ers-nircam/lib/python3.9/site-packages), Requirement.parse('jsonschema<4.10.0,>=4.0.1'), {'asdf'})\n",
      "  warnings.warn(\n",
      "\n",
      "2022-10-04 14:38:25,461 - stpipe.EurekaS1Pipeline - WARNING - /Users/megan/opt/anaconda3/envs/ers-nircam/lib/python3.9/site-packages/asdf/entry_points.py:46: AsdfWarning: asdf.resource_mappings plugin from package jwst==1.6.0 failed to load:\n",
      "\n",
      "ContextualVersionConflict: (jsonschema 4.16.0 (/Users/megan/opt/anaconda3/envs/ers-nircam/lib/python3.9/site-packages), Requirement.parse('jsonschema<4.10.0,>=4.0.1'), {'asdf'})\n",
      "  warnings.warn(\n",
      "\n",
      "2022-10-04 14:38:25,462 - stpipe.EurekaS1Pipeline - WARNING - /Users/megan/opt/anaconda3/envs/ers-nircam/lib/python3.9/site-packages/asdf/entry_points.py:46: AsdfWarning: asdf.resource_mappings plugin from package asdf==2.13.0 failed to load:\n",
      "\n",
      "VersionConflict: (jsonschema 4.16.0 (/Users/megan/opt/anaconda3/envs/ers-nircam/lib/python3.9/site-packages), Requirement.parse('jsonschema<4.10.0,>=4.0.1'))\n",
      "  warnings.warn(\n",
      "\n",
      "2022-10-04 14:38:25,462 - stpipe.EurekaS1Pipeline - INFO - First argument /Users/megan/Documents/Code/ERS_NIRCam/ERS_NIRCam/Uncalibrated/jw01366002001_04103_00001-seg001_nrcalong_uncal.fits does not appear to be a model\n",
      "2022-10-04 14:38:25,462 - stpipe.EurekaS1Pipeline - INFO - Starting calwebb_detector1 ...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Unable to fetch schema from non-file URL: http://stsci.edu/schemas/jwst_datamodel/ramp.schema",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m s1_meta \u001b[38;5;241m=\u001b[39m \u001b[43ms1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrampfitJWST\u001b[49m\u001b[43m(\u001b[49m\u001b[43meventlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mecf_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mecf_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Code/ERS_NIRCam/ERS_NIRCam/Eureka/src/eureka/S1_detector_processing/s1_process.py:94\u001b[0m, in \u001b[0;36mrampfitJWST\u001b[0;34m(eventlabel, ecf_path)\u001b[0m\n\u001b[1;32m     91\u001b[0m             hdulist[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mheader[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNDITHPTS\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     92\u001b[0m             hdulist[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mheader[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNRIMDTPT\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 94\u001b[0m         \u001b[43mEurekaS1Pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_eurekaS1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Calculate total run time\u001b[39;00m\n\u001b[1;32m     97\u001b[0m total \u001b[38;5;241m=\u001b[39m (time_pkg\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60.\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Code/ERS_NIRCam/ERS_NIRCam/Eureka/src/eureka/S1_detector_processing/s1_process.py:200\u001b[0m, in \u001b[0;36mEurekaS1Pipeline.run_eurekaS1\u001b[0;34m(self, filename, meta, log)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mramp_fit\u001b[38;5;241m.\u001b[39mcustom_exponents \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    197\u001b[0m             meta\u001b[38;5;241m.\u001b[39mdefault_ramp_fit_custom_exponents\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# Run Stage 1\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ers-nircam/lib/python3.9/site-packages/stpipe/step.py:483\u001b[0m, in \u001b[0;36mStep.run\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefetch(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 483\u001b[0m     step_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess() takes exactly\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ers-nircam/lib/python3.9/site-packages/jwst/pipeline/calwebb_detector1.py:71\u001b[0m, in \u001b[0;36mDetector1Pipeline.process\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     68\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStarting calwebb_detector1 ...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# open the input as a RampModel\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mdatamodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRampModel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# propagate output_dir to steps that might need it\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdark_current\u001b[38;5;241m.\u001b[39moutput_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dir\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ers-nircam/lib/python3.9/site-packages/jwst/datamodels/ramp.py:40\u001b[0m, in \u001b[0;36mRampModel.__init__\u001b[0;34m(self, init, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, init\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mRampModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# Implicitly create arrays\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpixeldq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpixeldq\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ers-nircam/lib/python3.9/site-packages/stdatamodels/model_base.py:174\u001b[0m, in \u001b[0;36mDataModel.__init__\u001b[0;34m(self, init, schema, memmap, pass_invalid_values, strict_validation, validate_on_assignment, cast_fits_arrays, validate_arrays, ignore_missing_extensions, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         schema \u001b[38;5;241m=\u001b[39m _DEFAULT_SCHEMA\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;66;03m# Create an AsdfFile so we can use its resolver for loading schemas\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m         schema \u001b[38;5;241m=\u001b[39m \u001b[43masdf_schema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolve_references\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema \u001b[38;5;241m=\u001b[39m mschema\u001b[38;5;241m.\u001b[39mmerge_property_trees(schema)\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# Provide the object as context to other classes and functions\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ers-nircam/lib/python3.9/site-packages/asdf/schema.py:431\u001b[0m, in \u001b[0;36mload_schema\u001b[0;34m(url, resolver, resolve_references, resolve_local_refs)\u001b[0m\n\u001b[1;32m    426\u001b[0m     resolver \u001b[38;5;241m=\u001b[39m extension\u001b[38;5;241m.\u001b[39mget_default_resolver()\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# We want to cache the work that went into constructing the schema, but returning\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;66;03m# the same object is treacherous, because users who mutate the result will not\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# expect that they're changing the schema everywhere.\u001b[39;00m\n\u001b[0;32m--> 431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[43m_load_schema_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolve_references\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolve_local_refs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ers-nircam/lib/python3.9/site-packages/asdf/schema.py:478\u001b[0m, in \u001b[0;36m_load_schema_cached\u001b[0;34m(url, resolver, resolve_references, resolve_local_refs)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;129m@lru_cache\u001b[39m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_schema_cached\u001b[39m(url, resolver, resolve_references, resolve_local_refs):\n\u001b[1;32m    477\u001b[0m     loader \u001b[38;5;241m=\u001b[39m _make_schema_loader(resolver)\n\u001b[0;32m--> 478\u001b[0m     schema, url \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolve_references \u001b[38;5;129;01mor\u001b[39;00m resolve_local_refs:\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresolve_refs\u001b[39m(node, json_id):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ers-nircam/lib/python3.9/site-packages/asdf/schema.py:355\u001b[0m, in \u001b[0;36m_make_schema_loader.<locals>.load_schema\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result, url\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# If not, this must be a URL (or missing).  Fall back to fetching\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;66;03m# the schema the old way:\u001b[39;00m\n\u001b[0;32m--> 355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ers-nircam/lib/python3.9/site-packages/asdf/schema.py:319\u001b[0m, in \u001b[0;36m_load_schema\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;129m@lru_cache\u001b[39m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_schema\u001b[39m(url):\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m url\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m url\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m url\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masdf://\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 319\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to fetch schema from non-file URL: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m url)\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m generic_io\u001b[38;5;241m.\u001b[39mget_file(url) \u001b[38;5;28;01mas\u001b[39;00m fd:\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(url, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m url\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Unable to fetch schema from non-file URL: http://stsci.edu/schemas/jwst_datamodel/ramp.schema"

     ]
    }
   ],
   "source": [
    "s1_meta = s1.rampfitJWST(eventlabel, ecf_path=ecf_path, input_meta=input_meta_S1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538fda9a",
   "metadata": {},
   "source": [
    "# Stage 2: Additional pre-spectral-extraction steps, such as assignment of the world coordinate system, flat fielding, wavelength calibration. Outputs calibrated 2D images.\n",
    "#### Most important keywords in the .ecf:\n",
    "1. skip_bkg_subtract - Kevin had this set to false?? Check this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ed2f621",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecffile = 'S2_' + eventlabel + '.ecf'\n",
    "input_meta_S2 = readECF.MetaClass(ecf_path, ecffile)\n",
    "input_meta_S2.skip_bkg_subtract = True\n",
    "input_meta_S2.hide_plots = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c985ca",
   "metadata": {},
   "source": [
    "### Let's run Stage 2!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5b39cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_meta = s2.calibrateJWST(eventlabel, ecf_path=ecf_path, s1_meta=s1_meta, input_meta=input_meta_S2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad296fa",
   "metadata": {},
   "source": [
    "# Stage 3: Identify source position, perform background subtraction, perform spectral extraction to produce time series of 1D extracted spectra.\n",
    "#### Most important keywords in the .ecf:\n",
    "1. ncpu - Number of CPUs on your machine. This won't affect the data reduction except to make it run faster if you are able to run it on more CPUs. You can change this number to fit whatever machine you're running on.\n",
    "2. ywindow and xwindow - These specify the region of the image that you're interested in performing background subtraction and spectral extraction on. Note that this is the *full* image, not just the window surrounding the spectral trace. For this demo, the ywindow is set to ignore reference pixels on the edges of the detector, and the xwindow is set to select the region of higher throughput where the spectral trace can actually be seen in the image. These values were selected based on viewing an image in ds9 or another fits file viewer and looking at the position of the spectral trace.\n",
    "\n",
    "#### The next several parameters have to do with the background subtraction. Eureka! performs background subtraction by identifying the spectral trace, masking out a region surrounding the spectral trace, and using the remaining pixels as the background.\n",
    "\n",
    "3. bg_hw - Defines the half-width of the masked area not included in background subtraction. In this example, a value of 14 means that 14 pixels both above and below the identified source position are excluded from each column. We tested a few different values and found that 14 minimized the MAD of the resulting light curves, as it was large enough to exclude contamination from the spectrum but not so large that the background subtraction was affected by having less pixels to estimate the background from.\n",
    "4. bg_deg - The background is subtracted by doing a column-by-column polynomial fit, and bg_deg defines the degree of that fit. Setting bg_deg = -1 will just calculate and subtract out a median for each column. For this reduction, bg_deg=1 removed the background sufficiently well.\n",
    "\n",
    "#### Now some parameters for how we'll do the spectral extraction!\n",
    "5. spec_hw - Defines the half-width of the region you extract the spectrum from. In this example, a value of 9 means that the extraction will be perfomed on a box of pixels extending 9 up and 9 down from the identified source position. We tested several values and found that a half-width of 9 minimized the MAD of the resulting light curves, as it was wide enough to catch the edges of the spectrum but not so wide that it added too much background contamination.\n",
    "\n",
    "#### Finally, some parameters for printing diagnostics and saving output.\n",
    "6. isplots_S3 - How many plots do you want to create? This can be set to 1, 3, or 5, where a bigger number will print out more different types of diagnostic plots. The default in this demo is 5 so that you can see all the diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ec09997",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecffile = 'S3_' + eventlabel + '.ecf'\n",
    "input_meta_S3 = readECF.MetaClass(ecf_path, ecffile)\n",
    "\n",
    "input_meta_S3.ncpu = 1\n",
    "input_meta_S3.xwindow = [4,64]\n",
    "input_meta_S3.ywindow = [4,1704]\n",
    "\n",
    "input_meta_S3.bg_hw = 14\n",
    "input_meta_S3.bg_deg = 1\n",
    "\n",
    "input_meta_S3.spec_hw = 9\n",
    "\n",
    "input_meta_S3.isplots_S3 = 3\n",
    "input_meta_S3.hide_plots = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4962857",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_spec, s3_meta = s3.reduce(eventlabel, ecf_path=ecf_path, s2_meta=s2_meta, input_meta=input_meta_S3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f69187",
   "metadata": {},
   "source": [
    "# Stage 4: Convert 1D extracted spectra to time series light curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7390ef5",
   "metadata": {},
   "source": [
    "#### Most important keywords in the .ecf:\n",
    "1. nspecchan - number of spectroscopic channels\n",
    "2. compute_white - whether to compute the white-light lightcurve\n",
    "3. wave_min and wave_max - the wavelength range in micron\n",
    "4. clip_unbinned and clip_binned - whether to perform sigma-clipping on the unbinned and/or binned 1D time series\n",
    "5. sigma - the number of sigmas a point must be from the rolling median to be considered an outlier\n",
    "\n",
    "#### Limb-darkening coefficients using exotic-ld (https://exotic-ld.readthedocs.io/en/latest/)\n",
    "6. compute_ld - whether to compute the limb-darkening coefficients with exotic-ld\n",
    "7. exotic_ld_direc - directory for ancillary files for exotic-ld (see documentation of exotic-ld)\n",
    "8. exotic_ld_grid - whether to use 3D or 1D stellar model grids\n",
    "9. exotic_ld_file - if you want to use custom throughput file (leave empty if using default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45532b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecffile = 'S4_' + eventlabel + '.ecf'\n",
    "input_meta_S4 = readECF.MetaClass(ecf_path, ecffile)\n",
    "\n",
    "\n",
    "input_meta_S4.nspecchan = 110\n",
    "input_meta_S4.wave_min = 2.405\n",
    "input_meta_S4.wave_max = 4.055\n",
    "\n",
    "input_meta_S4.compute_white = True \n",
    "\n",
    "input_meta_S4.clip_unbinned = False   \n",
    "input_meta_S4.clip_binned = True    \n",
    "input_meta_S4.sigma = 4     \n",
    "\n",
    "# Limb-darkening parameters needed to compute exotic-ld\n",
    "input_meta_S4.compute_ld = False\n",
    "input_meta_S4.exotic_ld_direc = '/data/exotic-ld_data/' \n",
    "input_meta_S4.exotic_ld_grid = '3D' \n",
    "input_meta_S4.exotic_ld_file = '/data/exotic-ld_data/NIRCam_throughput_full.csv' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf8f1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s4_spec, s4_lc, s4_meta = s4.genlc(eventlabel, ecf_path=ecf_path, s3_meta=s3_meta, input_meta=input_meta_S4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f6824f",
   "metadata": {},
   "source": [
    "# Stage 5: Light Curve Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f6c5e6",
   "metadata": {},
   "source": [
    "#### Most important keywords in the .ecf:\n",
    "1. fit_method - Which fitting method to use, options are: lsq, emcee, dynesty (can list multiple types separated by commas)\n",
    "2. run_myfuncs - What does the fit consist of? Options are: batman_tr (transit model), batman_ecl (eclipse model), sinusoid_pc (phase curve), expramp (exponential ramp), polynomial, step, and GP (Gaussian Process). Must list all models you want to use!\n",
    "3. use_generate_ld - Whether to use the 'exotic-ld' limb-darkening coefficients generated in Stage 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c07ae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecffile = 'S5_' + eventlabel + '.ecf'\n",
    "input_meta_S5 = readECF.MetaClass(ecf_path, ecffile)\n",
    "\n",
    "input_meta_S5.fit_method = '[emcee]'              \n",
    "input_meta_S5.run_myfuncs = '[batman_tr,polynomial]' \n",
    "\n",
    "input_meta_S5.use_generate_ld = 'exotic-ld' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4c1f81",
   "metadata": {},
   "source": [
    "#### Specific fitter parameters are in the cell below\n",
    "Least-squares (lsq)\n",
    "1. lsq_method - the scipy.optimize.minimize optimization method to use\n",
    "\n",
    "Markov Chain Monte Carlo (MCMC)\n",
    "1. lsq_first - whether to run a least-squares fit first and use as initial values for MCMC fit\n",
    "2. run_steps - number of steps\n",
    "3. run_nwalkers - number of walkers\n",
    "4. run_nburn - number of run_nsteps should be discarded as burn-in steps\n",
    "\n",
    "Dynesty (nested sampling)\n",
    "1. run_nlive - number of live points\n",
    "2. run_tol - tolerance value i.e. convergence criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce30698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitter parameters\n",
    "#lsq\n",
    "input_meta_S5.lsq_method = 'Powell'\n",
    "\n",
    "#mcmc\n",
    "input_meta_S5.lsq_first = True    \n",
    "input_meta_S5.run_nsteps = 500\n",
    "input_meta_S5.run_nwalkers = 100\n",
    "input_meta_S5.run_nburn = 100     \n",
    "\n",
    "#dynesty\n",
    "input_meta_S5.run_nlive = 1024    \n",
    "input_meta_S5.run_tol = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9e3ab2",
   "metadata": {},
   "source": [
    "\n",
    "## Important: Check your Parameter file (.epf file) for all parameter specific inputs e.g. prior types and ranges\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1437be",
   "metadata": {},
   "source": [
    "### Let's fit some light curves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0eb93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s5_meta = s5.fitlc(eventlabel, ecf_path=ecf_path, s4_meta=s4_meta, input_meta=input_meta_S5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d85e101",
   "metadata": {},
   "source": [
    "# Stage 6: Create Final Spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a006d3",
   "metadata": {},
   "source": [
    "#### Most important keywords in the .ecf:\n",
    "1. y_unit - For plotting the transmission spectrum, options include Rp/Rs, (Rp/Rs)^2, Fp/Fs\n",
    "2. y_sclar - Can be used to convert to ppm (1e6), percent (100), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d922718",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecffile = 'S6_' + eventlabel + '.ecf'\n",
    "input_meta_S6 = readECF.MetaClass(ecf_path, ecffile)\n",
    "\n",
    "input_meta_S6.y_unit = '(Rp/Rs)^2' \n",
    "input_meta_S6.y_scalar = 100 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790eb624",
   "metadata": {},
   "source": [
    "### Let's run the final stage to get a transmission spectrum!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116d15a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s6_meta = s6.plot_spectra(eventlabel, ecf_path=ecf_path, s5_meta=s5_meta, input_meta=input_meta_S6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {

   "display_name": "ers-nircam",
   "language": "python",
   "name": "ers-nircam"

  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
