{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "768c296d",
   "metadata": {},
   "source": [
    "# ERS NIRCam Demo with Eureka!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98121beb",
   "metadata": {},
   "source": [
    "\n",
    "#### Authors: Megan Mansfield and Eva-Maria Ahrer\n",
    " Hello! This notebook shows a full demonstration reducing and analyzing the NIRCam/F322W2 transit of WASP-39b from the JWST Transiting Exoplanet Early Release Science Program (ERS 1366). Following this pipeline, you should be able to reproduce the NIRCam spectrum presented in the main text of Ahrer et al. (2022). \n",
    " \n",
    "This data reduction uses the [Eureka!](https://github.com/kevin218/Eureka) pipeline. Before running this Jupyter Notebook, please follow the steps in \"README.md\" to set up an environment for this demonstration and install Eureka. Note that this demonstration is using a fixed version of Eureka! to ensure that no future updates break the example here, so even if you have the current version of Eureka! installed on your own machine you'll need to follow the set-up steps to ensure this demo works properly. For more information on Eureka! see its documentation or refer to Bell et al. (2022)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff54298",
   "metadata": {},
   "source": [
    "### First, let's import packages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ead275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./')\n",
    "sys.path.insert(0,'./')\n",
    "import eureka.S1_detector_processing.s1_process as s1\n",
    "import eureka.S2_calibrations.s2_calibrate as s2\n",
    "import eureka.S3_data_reduction.s3_reduce as s3\n",
    "import eureka.S4_generate_lightcurves.s4_genLC as s4\n",
    "import eureka.S5_lightcurve_fitting.s5_fit as s5\n",
    "import eureka.S6_planet_spectra.s6_spectra as s6\n",
    "from astroquery.mast import Observations\n",
    "import eureka.lib.mastDownload as md\n",
    "from astropy.io import ascii\n",
    "\n",
    "from eureka.lib import readECF\n",
    "\n",
    "eventlabel = 'nircam_wasp39b'\n",
    "ecf_path = './ecf/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc8ab40",
   "metadata": {},
   "source": [
    "### Next, download the data set.\n",
    "#### Data can be downloaded from MAST using Eureka!. Here we will go through important keywords to pull the correct data for this tutorial.\n",
    "1. proposal_id, observation, visit - All three are used to specify the exact observation you want to download for a given program. The proposal_id can be found by searching for the program from the list of accepted programs at https://www.stsci.edu/jwst/science-execution/approved-programs. After finding the correct program, click \"Visit Status Information\" to find the correct observation and visit numbers for the data set you'd like to download.\n",
    "\n",
    "2. calib_level, subgroup - These specify which level in the JWST pipeline you'd like to retrieve data products at and which data product you will get. calib_level=0 is raw, which you'll likely never want to download. calib_level=1, subgroup='UNCAL' downloads uncalibrated data and is the standard choice for this tutorial. However, you can also download data at level 2 and start from a later point in this notebook. If you set calib_level=2, subgroup='RATEINTS', skip Stage 1 below and start at Stage 2. If you set calib_level=2, subgroup='CALINTS', skip Stages 1 and 2 below and start at Stage 3. Note that if you do this you may get different results than in the paper because you'll be relying on the STScI JWST pipeline for Stages 1/2 instead of using Eureka!.\n",
    "\n",
    "3. download_dir - This is just a temporary storage location as the data is being gathered from MAST.\n",
    "\n",
    "4. final_dir - This is the final location where the downloaded data files will be stored. For this tutorial, since we're starting with uncalibrated data, we're placing it in a directory called \"./Uncalibrated\". You can name the directory anything you want as long as you provide the right directory name to Eureka! later in the tutorial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b26757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_id = '01366'\n",
    "observation = 2\n",
    "visit = 1\n",
    "\n",
    "calib_level = [1]\n",
    "subgroup = 'UNCAL'\n",
    "\n",
    "download_dir = './wasp39b'\n",
    "final_dir = './Uncalibrated/'\n",
    "\n",
    "# Apply standard filters to identify files for download\n",
    "table = md.filterJWST(proposal_id, observation, visit, calib_level, subgroup)\n",
    "\n",
    "# Download data products, returns manifest of files downloaded.\n",
    "manifest = Observations.download_products(table, curl_flag=False,\n",
    "                                          download_dir=download_dir)\n",
    "\n",
    "# Consolidate and move data into new directory\n",
    "md.consolidate(manifest, final_dir)\n",
    "\n",
    "# Delete empty temporary directory structure\n",
    "md.cleanup(download_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6b7d52",
   "metadata": {},
   "source": [
    "#### Note: Eureka! is divided into six \"Stages\". Each Stage has a corresponding Eureka! Control File or .ecf file, and in Stage 5 there's also a Eureka! Parameter File or .epf. \n",
    "These files are named \"S2_eventlabel.ecf\" where the first half of the name (S2, S3, etc.) refers to the Stage that .ecf file interacts with, and the second half refers to the \"eventlabel\" keyword we defined above. See the Eureka! documentation for a full description of each stage and all keywords in the .ecf files. Here we'll give a very brief summary of each Stage and discuss a few important keywords for reproducing the paper results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236a961d",
   "metadata": {},
   "source": [
    "# Stage 1: Correcting detector-level effects and fitting the up-the-ramp slope.\n",
    "#### Most important keywords in the .ecf:\n",
    "1. jump_rejection_threshold - this sets the sigma threshold for rejecting a jump in the up-the-ramp slope as due to a cosmic ray hit. The standard value in the jwst pipeline is 4.0, but this data reduction found a value of 6.0 produced better results.\n",
    "2. topdir - Edit this to make it the path to where you've downloaded the data for this demo. The path should look like this: /path/to/NIRCam_demo/wasp39b_data/\n",
    "3. inputdir - This keyword tells Eureka! where to look for the Uncalibrated outputs to feed into the Stage 1 code. This path is relative to \"topdir\". In this demo, we set inputdir=/Uncalibrated\n",
    "4. outputdir - This is where Eureka! will save all the Stage 2 outputs, including plots and log files. Here we set outputdir=/Stage1, which means the output files will be saved within a folder on the path /path/to/NIRCam_demo/NIRCam_full_data/Stage1/\n",
    "5. suffix - This is used to identify which subset of files from the ones downloaded from MAST will be used. For this data set, the long wavelength spectra are contained in files with the naming pattern '04103_\\*nrcalong_uncal'\n",
    "#### Note that topdir, inputdir, and outputdir work the same in every .ecf file, so in each file edit them so that \"inputdir\" points to the previous Stage's outputs, and \"outputdir\" points to where you want to save that Stage's outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa3919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecffile = 'S1_' + eventlabel + '.ecf'\n",
    "input_meta_S1 = readECF.MetaClass(ecf_path, ecffile)\n",
    "\n",
    "input_meta_S1.jump_rejection_threshold = 6.0\n",
    "input_meta_S1.topdir = '/storage/astro2/phrgmk/Data/JWST/NIRCam/WASP-39/'\n",
    "input_meta_S1.inputdir = input_meta_S1.topdir + '/Uncalibrated/'\n",
    "input_meta_S1.outputdir = input_meta_S1.topdir + '/Stage1'\n",
    "input_meta_S1.suffix = '04103_*nrcalong_uncal'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef77f50",
   "metadata": {},
   "source": [
    "### And that's it! Let's run Stage 1!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abecad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_meta = s1.rampfitJWST(eventlabel, ecf_path=ecf_path, input_meta=input_meta_S1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538fda9a",
   "metadata": {},
   "source": [
    "# Stage 2: Additional pre-spectral-extraction steps, such as assignment of the world coordinate system, flat fielding, wavelength calibration. Outputs calibrated 2D images.\n",
    "\n",
    "#### If you have downloaded the rateints.fits files start here!\n",
    "\n",
    "#### Most important keywords in the .ecf:\n",
    "1. skip_bkg_subtract - Background subtraction is skipped by default for time-series observations such as exoplanet transits.\n",
    "2. hide_plots - This keyword will close plots as they are created. It is very useful for avoiding memory issues if you are printing a large number of plots, so we recommend leaving it set to True.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed2f621",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecffile = 'S2_' + eventlabel + '.ecf'\n",
    "input_meta_S2 = readECF.MetaClass(ecf_path, ecffile)\n",
    "input_meta_S2.skip_bkg_subtract = True\n",
    "input_meta_S2.hide_plots = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e2b02c",
   "metadata": {},
   "source": [
    "#### If start running this notebook at this stage (using rateints.fits outputs), then you need to uncomment the lines in the cell below and define the topdir and inputdir parameters here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58ac5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_meta_S2.topdir = '/data/JWST/wasp39b/nircam_f322w2/'\n",
    "#input_meta_S2.inputdir = 'S1/nrcalong/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c985ca",
   "metadata": {},
   "source": [
    "### Let's run Stage 2!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5b39cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_meta = s2.calibrateJWST(eventlabel, ecf_path=ecf_path, s1_meta=s1_meta, input_meta=input_meta_S2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad296fa",
   "metadata": {},
   "source": [
    "# Stage 3: Identify source position, perform background subtraction, perform spectral extraction to produce time series of 1D extracted spectra.\n",
    "\n",
    "#### If you have downloaded the calints.fits files start here!\n",
    "\n",
    "#### Most important keywords in the .ecf:\n",
    "1. ncpu - Number of CPUs on your machine. This won't affect the data reduction except to make it run faster if you are able to run it on more CPUs. You can change this number to fit whatever machine you're running on.\n",
    "2. ywindow and xwindow - These specify the region of the image that you're interested in performing background subtraction and spectral extraction on. Note that this is the *full* image, not just the window surrounding the spectral trace. For this demo, the ywindow is set to ignore reference pixels on the edges of the detector, and the xwindow is set to select the region of higher throughput where the spectral trace can actually be seen in the image. These values were selected based on viewing an image in ds9 or another fits file viewer and looking at the position of the spectral trace.\n",
    "\n",
    "#### The next several parameters have to do with the background subtraction. Eureka! performs background subtraction by identifying the spectral trace, masking out a region surrounding the spectral trace, and using the remaining pixels as the background.\n",
    "\n",
    "3. bg_hw - Defines the half-width of the masked area not included in background subtraction. In this example, a value of 14 means that 14 pixels both above and below the identified source position are excluded from each column. We tested a few different values and found that 14 minimized the MAD of the resulting light curves, as it was large enough to exclude contamination from the spectrum but not so large that the background subtraction was affected by having less pixels to estimate the background from.\n",
    "4. bg_deg - The background is subtracted by doing a column-by-column polynomial fit, and bg_deg defines the degree of that fit. Setting bg_deg = -1 will just calculate and subtract out a median for each column. For this reduction, bg_deg=1 removed the background sufficiently well.\n",
    "\n",
    "#### Now some parameters for how we'll do the spectral extraction!\n",
    "5. spec_hw - Defines the half-width of the region you extract the spectrum from. In this example, a value of 9 means that the extraction will be perfomed on a box of pixels extending 9 up and 9 down from the identified source position. We tested several values and found that a half-width of 9 minimized the MAD of the resulting light curves, as it was wide enough to catch the edges of the spectrum but not so wide that it added too much background contamination.\n",
    "\n",
    "#### Finally, some parameters for printing diagnostics and saving output.\n",
    "6. isplots_S3 - How many plots do you want to create? This can be set to 1, 3, or 5, where a bigger number will print out more different types of diagnostic plots. The default in this demo is 5 so that you can see all the diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec09997",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecffile = 'S3_' + eventlabel + '.ecf'\n",
    "input_meta_S3 = readECF.MetaClass(ecf_path, ecffile)\n",
    "\n",
    "input_meta_S3.ncpu = 1\n",
    "input_meta_S3.xwindow = [4,64]\n",
    "input_meta_S3.ywindow = [4,1704]\n",
    "\n",
    "input_meta_S3.bg_hw = 14\n",
    "input_meta_S3.bg_deg = 1\n",
    "\n",
    "input_meta_S3.spec_hw = 9\n",
    "\n",
    "input_meta_S3.isplots_S3 = 3\n",
    "input_meta_S3.hide_plots = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff99f21",
   "metadata": {},
   "source": [
    "#### If you started with the Stage 2 output files (calints.fits), then you need to uncomment the lines in the cell below and define the topdir and inputdir parameters here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3830eb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_meta_S3.topdir = '/data/JWST/wasp39b/nircam_f322w2'\n",
    "#input_meta_S3.inputdir = 'S2/nrcalong/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4962857",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_spec, s3_meta = s3.reduce(eventlabel, ecf_path=ecf_path, s2_meta=s2_meta, input_meta=input_meta_S3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f69187",
   "metadata": {},
   "source": [
    "# Stage 4: Convert 1D extracted spectra to time series light curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7390ef5",
   "metadata": {},
   "source": [
    "#### Most important keywords in the .ecf:\n",
    "1. nspecchan - number of spectroscopic channels\n",
    "2. compute_white - whether to compute the white-light lightcurve\n",
    "3. wave_min and wave_max - the wavelength range in micron\n",
    "4. clip_unbinned and clip_binned - whether to perform sigma-clipping on the unbinned and/or binned 1D time series\n",
    "5. sigma - the number of sigmas a point must be from the rolling median to be considered an outlier\n",
    "\n",
    "#### Limb-darkening coefficients using exotic-ld (https://exotic-ld.readthedocs.io/en/latest/)\n",
    "6. compute_ld - whether to compute the limb-darkening coefficients with exotic-ld\n",
    "7. exotic_ld_direc - directory for ancillary files for exotic-ld (see documentation of exotic-ld)\n",
    "8. exotic_ld_grid - whether to use 3D or 1D stellar model grids\n",
    "9. exotic_ld_file - if you want to use custom throughput file (leave empty if using default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45532b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecffile = 'S4_' + eventlabel + '.ecf'\n",
    "input_meta_S4 = readECF.MetaClass(ecf_path, ecffile)\n",
    "\n",
    "\n",
    "input_meta_S4.nspecchan = 110\n",
    "input_meta_S4.wave_min = 2.405\n",
    "input_meta_S4.wave_max = 4.055\n",
    "\n",
    "input_meta_S4.compute_white = True \n",
    "\n",
    "input_meta_S4.clip_unbinned = False   \n",
    "input_meta_S4.clip_binned = True    \n",
    "input_meta_S4.sigma = 4     \n",
    "\n",
    "# Limb-darkening parameters needed to compute exotic-ld\n",
    "input_meta_S4.compute_ld = False\n",
    "input_meta_S4.exotic_ld_direc = '/data/exotic-ld_data/' \n",
    "input_meta_S4.exotic_ld_grid = '3D' \n",
    "input_meta_S4.exotic_ld_file = '/data/exotic-ld_data/NIRCam_throughput_full.csv' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf8f1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s4_spec, s4_lc, s4_meta = s4.genlc(eventlabel, ecf_path=ecf_path, s3_meta=s3_meta, input_meta=input_meta_S4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f6824f",
   "metadata": {},
   "source": [
    "# Stage 5: Light Curve Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f6c5e6",
   "metadata": {},
   "source": [
    "#### Most important keywords in the .ecf:\n",
    "1. fit_method - Which fitting method to use, options are: lsq, emcee, dynesty (can list multiple types separated by commas)\n",
    "2. run_myfuncs - What does the fit consist of? Options are: batman_tr (transit model), batman_ecl (eclipse model), sinusoid_pc (phase curve), expramp (exponential ramp), polynomial, step, and GP (Gaussian Process). Must list all models you want to use!\n",
    "3. use_generate_ld - Whether to use the 'exotic-ld' limb-darkening coefficients generated in Stage 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c07ae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecffile = 'S5_' + eventlabel + '.ecf'\n",
    "input_meta_S5 = readECF.MetaClass(ecf_path, ecffile)\n",
    "\n",
    "input_meta_S5.fit_method = '[emcee]'              \n",
    "input_meta_S5.run_myfuncs = '[batman_tr,polynomial]' \n",
    "\n",
    "input_meta_S5.use_generate_ld = 'exotic-ld' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4c1f81",
   "metadata": {},
   "source": [
    "#### Specific fitter parameters are in the cell below\n",
    "Least-squares (lsq)\n",
    "1. lsq_method - the scipy.optimize.minimize optimization method to use\n",
    "\n",
    "Markov Chain Monte Carlo (MCMC)\n",
    "1. lsq_first - whether to run a least-squares fit first and use as initial values for MCMC fit\n",
    "2. run_steps - number of steps\n",
    "3. run_nwalkers - number of walkers\n",
    "4. run_nburn - number of run_nsteps should be discarded as burn-in steps\n",
    "\n",
    "Dynesty (nested sampling)\n",
    "1. run_nlive - number of live points\n",
    "2. run_tol - tolerance value i.e. convergence criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce30698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitter parameters\n",
    "#lsq\n",
    "input_meta_S5.lsq_method = 'Powell'\n",
    "\n",
    "#mcmc\n",
    "input_meta_S5.lsq_first = True    \n",
    "input_meta_S5.run_nsteps = 500\n",
    "input_meta_S5.run_nwalkers = 100\n",
    "input_meta_S5.run_nburn = 100     \n",
    "\n",
    "#dynesty\n",
    "input_meta_S5.run_nlive = 1024    \n",
    "input_meta_S5.run_tol = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9e3ab2",
   "metadata": {},
   "source": [
    "\n",
    "## Important: Check your Parameter file (.epf file) for all parameter specific inputs e.g. prior types and ranges\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1437be",
   "metadata": {},
   "source": [
    "### Let's fit some light curves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0eb93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s5_meta = s5.fitlc(eventlabel, ecf_path=ecf_path, s4_meta=s4_meta, input_meta=input_meta_S5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d85e101",
   "metadata": {},
   "source": [
    "# Stage 6: Create Final Spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a006d3",
   "metadata": {},
   "source": [
    "#### Most important keywords in the .ecf:\n",
    "1. y_unit - For plotting the transmission spectrum, options include Rp/Rs, (Rp/Rs)^2, Fp/Fs\n",
    "2. y_sclar - Can be used to convert to ppm (1e6), percent (100), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d922718",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecffile = 'S6_' + eventlabel + '.ecf'\n",
    "input_meta_S6 = readECF.MetaClass(ecf_path, ecffile)\n",
    "\n",
    "input_meta_S6.y_unit = '(Rp/Rs)^2' \n",
    "input_meta_S6.y_scalar = 100 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790eb624",
   "metadata": {},
   "source": [
    "### Let's run the final stage to get a transmission spectrum!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116d15a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s6_meta = s6.plot_spectra(eventlabel, ecf_path=ecf_path, s5_meta=s5_meta, input_meta=input_meta_S6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
